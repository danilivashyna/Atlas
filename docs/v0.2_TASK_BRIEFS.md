# v0.2 Task Briefs — 8 Parallel Features

**Status**: All 8 branches created, PRs #5-12 ready for task assignment
**Timeline**: 3-4 weeks to v0.2.0-beta release
**Testing**: All existing tests passing (91+)

---

## 📍 Branch ↔ PR Mapping

| PR  | Branch | Feature | Status |
|-----|--------|---------|--------|
| #5  | `feature/v0.2-01-encoder-bert` | TextEncoder5D | 🟡 Ready |
| #6  | `feature/v0.2-02-decoder-transformer` | Interpretable Decoder | 🟡 Ready |
| #7  | `feature/v0.2-03-api-hier-ops` | Hierarchical API | 🟡 Ready |
| #8  | `feature/v0.2-04-losses-hier` | Hierarchical Losses | 🟡 Ready |
| #9  | `feature/v0.2-05-distill-teacher` | Distillation | 🟡 Ready |
| #10 | `feature/v0.2-06-metrics-hier` | Metrics Suite | 🟡 Ready |
| #11 | `feature/v0.2-07-benchmarks` | Benchmarks | 🟡 Ready |
| #12 | `feature/v0.2-08-docs-demos-cli` | Docs/Demos/CLI | 🟡 Ready |

---

# 🎯 TASK BRIEFS — Copy-Paste for Agent Tasks

## PR #5 — v0.2-01: TextEncoder5D (BERT 384D→5D + PCA)

**Repository**: danilivashyna/Atlas
**Branch**: `feature/v0.2-01-encoder-bert`
**PR**: #5

### Goal
Implement TextEncoder5D based on sentence-transformers/all-MiniLM-L6-v2 (384D) → PCA projection to 5D, normalization [-1,1], fallback to SimpleSemanticEncoder (no internet/in CI). Integrate into /encode via ATLAS_ENCODER_TYPE environment variable.

### Scope
- `src/atlas/encoders/text_encoder_5d.py` (+ update `__init__.py`)
- PCA matrix/training offline → store fixed matrix/weights in repo
- Integration into `src/atlas/api/app.py` via ATLAS_ENCODER_TYPE environment variable
- `tests/test_text_encoder_5d.py` (≥22 tests, 2 skip acceptable)
- README usage example

### Acceptance Criteria
- ✅ `pytest`: All existing tests pass (91+ baseline); new 5D test suite passes
- ✅ `/encode` endpoint not broken; with `ATLAS_ENCODER_TYPE=TextEncoder5D` returns 5D output
- ✅ Fallback correct if sentence-transformers unavailable
- ✅ Code formatted, type hints complete, docstrings present, no new DeprecationWarnings

### How to Run
```bash
export ATLAS_ENCODER_TYPE=TextEncoder5D
pytest tests/test_text_encoder_5d.py -v
pytest -q  # All tests
uvicorn src.atlas.api.app:app --port 8010
# Test: curl -X POST http://localhost:8010/encode -H "Content-Type: application/json" -d '{"text":"hello"}'
```

### Out of Scope
- PCA training at runtime
- Changes to API contract

---

## PR #6 — v0.2-02: Interpretable Transformer Decoder

**Repository**: danilivashyna/Atlas
**Branch**: `feature/v0.2-02-decoder-transformer`
**PR**: #6

### Goal
MVP of interpretable decoder: 5D → text + extraction of reasoning by dimensions. Greedy generation or template-based (no heavy dependencies).

### Scope
- `src/atlas/decoders/interpretable_decoder.py` (+ update `__init__.py`)
- Simple greedy or template-based generator
- `Reasoning` / `PathReasoning` class with per-dimension contribution
- `tests/test_interpretable_decoder.py` (≥10–13 tests)

### Acceptance Criteria
- ✅ `pytest` green
- ✅ Reasoning format stable: list of `{dim, weight/score, evidence/labels}`
- ✅ CPU speed acceptable (~<120ms on short examples, not strict)
- ✅ No changes to public API `/decode`

### How to Run
```bash
pytest tests/test_interpretable_decoder.py -v
pytest -q
uvicorn src.atlas.api.app:app --port 8010
# Test: curl -X POST http://localhost:8010/decode -H "Content-Type: application/json" -d '{"embedding":[...]}'
```

### Out of Scope
- Heavy models or full-featured LM
- Complex decoding logic

---

## PR #7 — v0.2-03: Hierarchical API Endpoints (/encode_h, /decode_h, /explain_h)

**Repository**: danilivashyna/Atlas
**Branch**: `feature/v0.2-03-api-hier-ops`
**PR**: #7

### Goal
Add and document `/encode_h`, `/decode_h`, `/explain_h` endpoints (Pydantic v2 models, OpenAPI).

### Scope
- `src/atlas/api/app.py`: endpoints + tags "Hierarchical"
- `src/atlas/api/models.py`: schema definitions for EncodeH/DecodeH/ExplainH request/response
- `tests/test_api_smoke.py`: smoke tests for new routes
- `docs/HIERARCHICAL_API.md` or README section: payload/response examples

### Acceptance Criteria
- ✅ `pytest` green
- ✅ OpenAPI describes all parameters and includes examples
- ✅ Responses contain `trace_id`, `timestamp` (UTC ISO 8601 "Z")
- ✅ `/docs` renders new endpoints correctly

### How to Run
```bash
pytest tests/test_api_smoke.py -v -k "encode_h or decode_h or explain_h"
pytest -q
uvicorn src.atlas.api.app:app --port 8010
# Visit: http://localhost:8010/docs
```

### Out of Scope
- Complex business logic for decoding (stubs acceptable)
- Deep integration with hierarchical training

---

## PR #8 — v0.2-04: Hierarchical Losses (Orthogonality, Sparsity, Entropy)

**Repository**: danilivashyna/Atlas
**Branch**: `feature/v0.2-04-losses-hier`
**PR**: #8

### Goal
Implement set of differentiable losses for 5D: axis orthogonality, L1/sparsity, router entropy.

### Scope
- `src/atlas/training/losses.py`: `OrthogonalityLoss`, `SparsityLoss`, `RouterEntropyLoss`
- `tests/test_losses.py`: formula correctness, edge cases, numerical stability
- `docs/LOSS_FUNCTIONS_v0.2.md`: brief descriptions and formulas

### Acceptance Criteria
- ✅ `pytest` green
- ✅ Clean numerical tests without flakes
- ✅ Loss functions framework-agnostic (NumPy/PyTorch stub as needed)
- ✅ Loss values reasonable: not NaN/Inf on valid inputs

### How to Run
```bash
pytest tests/test_losses.py -v
pytest -q
# Manual check: python -c "from src.atlas.training.losses import OrthogonalityLoss; print(OrthogonalityLoss())"
```

### Out of Scope
- Full trainer integration
- Advanced optimization tricks

---

## PR #9 — v0.2-05: Teacher → Student Distillation

**Repository**: danilivashyna/Atlas
**Branch**: `feature/v0.2-05-distill-teacher`
**PR**: #9

### Goal
Distillation scaffold: load teacher, load student, training steps, simple metric. CLI for training.

### Scope
- `src/atlas/training/distill.py`: `Distiller` class with `step()`, `load_teacher()`, `load_student()`
- `src/atlas/training/configs.py`: dataclass with paths/hyperparameters
- `tools/train_distill.py`: CLI with `--teacher`, `--student`, `--epochs` etc.
- `docs/distillation_quickstart.md`: usage guide
- `tests/test_distill_smoke.py`: dry-run 1–2 iterations on CPU, no downloads

### Acceptance Criteria
- ✅ `pytest` green without network
- ✅ CLI runs: `python tools/train_distill.py --help`
- ✅ Training logs and artifacts saved to `./runs/`
- ✅ Graceful handling of missing weights (skip if not available)

### How to Run
```bash
pytest tests/test_distill_smoke.py -v
pytest -q
python tools/train_distill.py --help
python tools/train_distill.py --epochs 1 --batch-size 2  # Dry-run
```

### Out of Scope
- Real large-scale models or lengthy training
- Advanced optimization strategies

---

## PR #10 — v0.2-06: Metrics Suite (H-Coherence, H-Stability, H-Diversity)

**Repository**: danilivashyna/Atlas
**Branch**: `feature/v0.2-06-metrics-hier`
**PR**: #10

### Goal
Implement metrics and minimal integration into reporting.

### Scope
- `src/atlas/metrics/metrics_hier.py`: `coherence()`, `stability()`, `diversity()` functions
- `tests/test_metrics_hier.py`: deterministic examples, edge cases
- `docs/METRICS_v0.2.md`: formulas, interpretation, calculation examples

### Acceptance Criteria
- ✅ `pytest` green
- ✅ Metrics pure (no external models), NumPy-based
- ✅ Documentation: calculation examples on small arrays
- ✅ Output values sensible: 0 ≤ value ≤ 1 (or appropriate range)

### How to Run
```bash
pytest tests/test_metrics_hier.py -v
pytest -q
python -c "from src.atlas.metrics.metrics_hier import coherence; print(coherence([[1,0,0,0,0]]))"
```

### Out of Scope
- Advanced visualizations
- Streaming metrics computation

---

## PR #11 — v0.2-07: Benchmarks (pytest-benchmark + Scenarios)

**Repository**: danilivashyna/Atlas
**Branch**: `feature/v0.2-07-benchmarks`
**PR**: #11

### Goal
Benchmark scenarios for latency/throughput/decoder reasoning.

### Scope
- `tests/benchmarks/test_bench_encoder.py`: latency benchmarks
- `tests/benchmarks/test_bench_decoder.py`: decoding speed benchmarks
- Integration with pytest-benchmark (skip if not installed)
- `docs/BENCHMARKS.md`: how to run and interpret results

### Acceptance Criteria
- ✅ `pytest` green; benchmarks marked as skipped without package
- ✅ Clear parameters: input sizes, repetition count
- ✅ No flaky/unstable dependencies
- ✅ Results reproducible on same hardware

### How to Run
```bash
pytest tests/benchmarks/ -v  # Or skipped if pytest-benchmark not present
pytest -q
# With pytest-benchmark installed:
pytest tests/benchmarks/ --benchmark-only
```

### Out of Scope
- CI artifact publishing
- Hardware-specific tuning

---

## PR #12 — v0.2-08: Docs, Demos, CLI

**Repository**: danilivashyna/Atlas
**Branch**: `feature/v0.2-08-docs-demos-cli`
**PR**: #12

### Goal
Update documentation and add CLI commands (`encode`, `decode`, `explain`). Minimal smoke tests.

### Scope
- `docs/QUICK_REFERENCE.md` / `docs/v0.2_DEVELOPMENT_STATUS.md` / README: updated sections
- `tools/atlas_cli.py`: CLI with `encode`, `decode`, `explain` commands + `--help`
- Examples: command outputs and response samples
- `tests/test_cli_smoke.py`: smoke tests for CLI

### Acceptance Criteria
- ✅ `pytest` green
- ✅ CLI works without network/external downloads
- ✅ `python tools/atlas_cli.py --help` displays all commands
- ✅ Documentation has current examples and usage patterns

### How to Run
```bash
pytest tests/test_cli_smoke.py -v
pytest -q
python tools/atlas_cli.py --help
python tools/atlas_cli.py encode "hello world"
python tools/atlas_cli.py decode "[1, 0.5, -0.3, 0.2, -0.1]"
```

### Out of Scope
- Jupyter/Colab notebooks (can be future work with link)
- Advanced CLI features (server mode, batch processing in v0.2)

---

# 📋 Universal Finalization Steps (All PRs)

After implementation and all tests pass:

### 1. Mark as Ready & Request Review
```bash
gh pr ready <N> --repo danilivashyna/Atlas
gh pr edit <N> --repo danilivashyna/Atlas --add-reviewer danilivashyna --add-label "v0.2"
```

### 2. Verify CI Locally & Remote
```bash
pytest -q  # Local
gh run list -L 2  # Check latest CI runs
```

### 3. After Green CI — Squash Merge
```bash
gh pr merge <N> --repo danilivashyna/Atlas --squash --delete-branch
```

---

# ✍️ PR Description Template

Use this template for each PR body on GitHub:

```markdown
## Goal
[Brief description of what is implemented]

## Scope
- Module 1 changes
- Module 2 changes
- New files: file1.py, file2.py
- Test file: test_*.py

## Acceptance Criteria
- [x] pytest all tests passing (N tests, M skipped if applicable)
- [x] API compatibility maintained
- [x] No new DeprecationWarnings
- [x] Docstrings and type hints complete
- [x] [Feature-specific criterion]

## How to Test
```bash
pytest tests/test_*.py -v
pytest -q  # All tests
[specific CLI/curl examples if applicable]
```

## Notes
- [Risk/limitation 1]
- [Risk/limitation 2]
- Depends on: [if applicable]

## Checklist
- [ ] Tests passing locally: `pytest -q`
- [ ] No new warnings: `pytest -q 2>&1 | grep -i warning`
- [ ] Type checking clean (mypy if configured)
- [ ] Code formatted: `black src/ --check` (if configured)
- [ ] Ready for review: all acceptance criteria met
```

---

# 🚀 Quick Command Reference

### Check All Branches Exist
```bash
git branch -a | grep feature/v0.2
```

### Switch to a Branch
```bash
git checkout feature/v0.2-01-encoder-bert
```

### See Latest Commit on Branch
```bash
git log -1 --oneline feature/v0.2-01-encoder-bert
```

### Run All Tests After Implementation
```bash
pytest -q
```

### Run Tests for One PR's Branch
```bash
git checkout feature/v0.2-05-distill-teacher
pytest tests/test_distill_smoke.py -v
```

### View PR Body/Description
```bash
gh pr view 5 --repo danilivashyna/Atlas --json body
```

### Update PR Description After Implementation
```bash
gh pr edit 5 --repo danilivashyna/Atlas --body-file pr_body.md
```

---

# 📊 Implementation Order Recommendation

**Parallel Development** (recommended):

| Phase | Features | Dependencies | Timeline |
|-------|----------|--------------|----------|
| **1** | #5 (Encoder), #6 (Decoder) | None | Week 1 |
| **2** | #7 (API), #8 (Losses), #9 (Distill) | Depends on #5, #6 | Week 2 |
| **3** | #10 (Metrics), #11 (Benchmarks), #12 (Docs) | Depends on #5-9 | Week 2-3 |
| **Merge** | All PRs merged to main | All phases complete | Week 3 |
| **Release** | Tag v0.2.0-beta | All tests >80% coverage, CI green | Week 3-4 |

---

# ✅ Status Tracking

**Completed**:
- ✅ 8 feature branches created locally + pushed to GitHub
- ✅ 8 draft PRs created (#5-12) with skeleton code for #5, #6
- ✅ 91 existing tests still passing
- ✅ CI/CD pipeline verified working
- ✅ All briefs prepared

**Next Steps**:
- 🔄 Assign developers to each PR (round-robin)
- 🔄 Each developer implements feature per brief
- 🔄 Convert PR from draft → ready when complete
- 🔄 Request review from @danilivashyna
- 🔄 Merge after approval
- 🔄 Tag v0.2.0-beta after all 8 PRs merged

---

## 📞 Support

- **Questions about brief**: Check "Goal" and "Scope" sections
- **Test failures**: Run `pytest -v` to see detailed output
- **GitHub CLI help**: `gh pr --help` or see GITHUB_CLI_CHEATSHEET.md
- **Stuck on implementation**: Comment in PR with question for review

---

**Last Updated**: 2025-10-20
**Branch Status**: All 8 ready for development
**Next Review**: After first batch of PRs converted to ready status
