# Atlas v0.3: Memory Persistence & Backends

## Overview

Memory persistence layer provides durable storage for semantic vectors with pluggable backends.

Currently supported:
- **inproc** (default): In-process in-memory store (MappaMemory). Fast, no persistence.
- **sqlite**: SQLite-backed persistent store. Suitable for development and deployment.

## Architecture

```
Application
    ↓
Memory API Routes (/memory/*)
    ↓
get_memory() factory
    ↓
Backend (inproc | sqlite)
    ↓
Store (5D vectors + metadata)
```

### Data Model

Each memory record contains:
- **id** (str): Unique identifier
- **vector** (list[5 float]): 5D semantic vector
- **meta** (dict, optional): User metadata (e.g., title, source, path)

### Similarity Search

Cosine similarity computed on-the-fly:

```
similarity(query, target) = dot(query, target) / (||query|| * ||target||)
```

Returns top-k results sorted by descending score.

## Configuration

### Environment Variables

```bash
# Memory backend selection
export ATLAS_MEMORY_BACKEND=inproc        # default: in-process
export ATLAS_MEMORY_BACKEND=sqlite        # SQLite persistent

# Memory feature flag
export ATLAS_MEMORY_MODE=on               # default: enabled
export ATLAS_MEMORY_MODE=off              # disable all memory operations
```

### Database Location

For SQLite backend:
- Default path: `$TMPDIR/atlas_memory.db` (or system temp)
- To specify custom path, pass `db_path` parameter when initializing backend (currently requires code change; future: env var)

## API Endpoints

All endpoints use JSON request/response bodies.

### Write a Vector

```
POST /memory/write
```

**Request:**
```json
{
  "id": "doc1",
  "vector": [0.1, 0.0, 0.8, 0.0, 0.2],
  "meta": {"title": "Deep learning advances", "source": "arxiv"}
}
```

**Response:**
```json
{
  "ok": true
}
```

### Query Similar Vectors

```
POST /memory/query
```

**Request:**
```json
{
  "vector": [0.1, 0.0, 0.7, 0.0, 0.2],
  "top_k": 3
}
```

**Response:**
```json
{
  "items": [
    {
      "id": "doc1",
      "score": 0.98,
      "vector": [0.1, 0.0, 0.8, 0.0, 0.2],
      "meta": {"title": "Deep learning advances", "source": "arxiv"}
    },
    ...
  ]
}
```

### Flush All Records

```
POST /memory/flush
```

**Request:** (empty body)

**Response:**
```json
{
  "removed": 2
}
```

### Bulk Load from JSONL

```
POST /memory/load
```

**Request:**
```json
{
  "path": "/path/to/data.jsonl"
}
```

**Response:**
```json
{
  "loaded": 42
}
```

Each line in JSONL must be a JSON object:
```json
{"id": "doc1", "vector": [0.1, 0.0, 0.8, 0.0, 0.2], "meta": {"title": "..."}}
```

### Get Statistics

```
GET /memory/stats
```

**Response:**
```json
{
  "backend": "sqlite",
  "count": 42,
  "path": "/tmp/atlas_memory.db",
  "size_bytes": 16384
}
```

## Summarize Integration

The `/summarize` endpoint integrates with memory for evidence blending.

New request parameters:
- `use_memory` (bool, default: true): Enable memory blending
- `memory_top_k` (int, default: 3): Number of memory items to retrieve
- `memory_weight` (float, default: 0.25): Weight for memory evidence (0.0 to 1.0)

**Example:**

```bash
curl -sS http://localhost:8010/summarize \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "text": "Machine learning powers modern AI...",
    "target_tokens": 50,
    "mode": "compress",
    "epsilon": 0.05,
    "preserve_order": true,
    "use_memory": true,
    "memory_top_k": 5,
    "memory_weight": 0.3
  }' | jq .
```

Blending formula per dimension:
```
combined_evidence = local_evidence * (1 - memory_weight) + memory_evidence * memory_weight
```

## Examples

### Using SQLite Backend

```bash
# Start server with SQLite
export ATLAS_MEMORY_BACKEND=sqlite
export ATLAS_SUMMARY_MODE=proportional
uvicorn src.atlas.api.app:app --port 8010
```

### Write and Query

```bash
# Write vector
curl -sS http://localhost:8010/memory/write \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "id": "doc1",
    "vector": [0.1, 0.0, 0.8, 0.0, 0.2],
    "meta": {"title": "Deep learning"}
  }'

# Query
curl -sS http://localhost:8010/memory/query \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "vector": [0.1, 0.0, 0.7, 0.0, 0.2],
    "top_k": 3
  }' | jq .
```

### Bulk Load

```bash
# Create JSONL file
cat > data.jsonl <<EOF
{"id": "doc1", "vector": [0.1, 0.0, 0.8, 0.0, 0.2], "meta": {"title": "doc1"}}
{"id": "doc2", "vector": [0.2, 0.3, 0.4, 0.1, 0.0], "meta": {"title": "doc2"}}
EOF

# Load
curl -sS http://localhost:8010/memory/load \
  -H 'Content-Type: application/json' \
  --data-binary '{"path": "./data.jsonl"}'

# Check stats
curl -sS http://localhost:8010/memory/stats | jq .
```

## Graceful Degradation

- **Memory unavailable**: Summarize completes without memory blending. Fallback to local evidence only.
- **Backend error**: Operations fail with HTTP 500 + error message. Caller should retry or disable memory.
- **Empty memory**: Query returns empty list. Summarizer uses local evidence only.

## Limitations (v0.3)

1. No vector index (Faiss, HNSW, etc.). O(n) similarity search. Acceptable for <100k vectors.
2. SQLite writes are sequential. High concurrency may see contention.
3. No TTL/expiration. Records persist until explicit flush.
4. Metadata is stored as JSON string. No structured query support.
5. No backup/replication. Use external tools if durability required.

## Future Enhancements

- Vector indices (Faiss, HNSW, Annoy) for fast ANN search
- Redis backend for distributed cache
- TTL support for automatic expiration
- Structured metadata queries (SQL-like)
- Replication and backup
