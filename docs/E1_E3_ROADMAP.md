# Atlas Œ≤ ‚Äî E1-E3 Development Roadmap

**–§–æ–∫—É—Å:** API –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã ‚Üí –ò–Ω–¥–µ–∫—Å—ã ‚Üí –ú–µ—Ç—Ä–∏–∫–∏ (–±–∞–∑–æ–≤—ã–π –∫–∞—Ä–∫–∞—Å)  
**–ü–µ—Ä–∏–æ–¥:** 2‚Äì3 –Ω–µ–¥–µ–ª–∏, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞  
**–í–µ—Ç–∫–∏:** `feature/E1-*`, `feature/E2-*`, `feature/E3-*`  
**PR —Ä–∞–∑–º–µ—Ä:** 200‚Äì400 —Å—Ç—Ä–æ–∫ max, "–æ–¥–Ω–∞ –º—ã—Å–ª—å ‚Äî –æ–¥–∏–Ω PR"

---

## E1 ‚Äî API & –ö–æ–Ω—Ç—Ä–∞–∫—Ç—ã (–Ω–µ–¥–µ–ª—è 1)

### 1.1: Pydantic-—Å—Ö–µ–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–æ–≤

**–ú–æ–¥—É–ª—å:** `src/atlas/api/schemas.py`

```python
# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–ª–∏ –º–∞–ø–ø–∏–º –≤—Ä—É—á–Ω—É—é –∏–∑ configs/api/schemas.json
from pydantic import BaseModel
from typing import List, Optional

class EncodeRequest(BaseModel):
    text: str
    metadata: Optional[dict] = None

class EncodeResponse(BaseModel):
    vector: List[float]

class SearchRequest(BaseModel):
    query: str
    levels: List[str] = ["sentence", "paragraph", "document"]
    top_k: int = 10
    fuse: str = "RRF"

class SearchResponse(BaseModel):
    hits: List[dict]
    debug: Optional[dict] = None

# ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ schemas
```

**Acceptance:**
- ‚úÖ `from atlas.api.schemas import EncodeRequest` —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚úÖ `make validate` üü¢
- ‚úÖ `pytest tests/test_api_schemas.py` –ø—Ä–æ—Ö–æ–¥–∏—Ç

**PR:** `feature/E1-1-pydantic-schemas` (150‚Äì200 —Å—Ç—Ä–æ–∫)

---

### 1.2: FastAPI –º–∞—Ä—à—Ä—É—Ç—ã –ø–æ routes.yaml

**–ú–æ–¥—É–ª—å:** `src/atlas/api/routes.py`

```python
from fastapi import FastAPI, HTTPException
from src.atlas.configs import ConfigLoader
from src.atlas.api.schemas import (
    EncodeRequest, EncodeResponse,
    SearchRequest, SearchResponse,
    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ
)

app = FastAPI(title="Atlas Œ≤ API", version="0.2.0")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
routes_cfg = ConfigLoader.get_api_routes()

@app.get("/health")
async def health():
    return {"status": "ok"}

@app.post("/encode")
async def encode(req: EncodeRequest) -> EncodeResponse:
    # TODO: —Ä–µ–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ E1.3
    return EncodeResponse(vector=[0.0] * 384)

@app.post("/search")
async def search(req: SearchRequest) -> SearchResponse:
    # TODO: —Ä–µ–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ E1.3
    return SearchResponse(hits=[])

# ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ 8 endpoints –∏–∑ routes.yaml
```

**Acceptance:**
- ‚úÖ `uvicorn src.atlas.api.app:app` —Å—Ç–∞—Ä—Ç—É–µ—Ç
- ‚úÖ `curl http://localhost:8010/health` ‚Üí 200
- ‚úÖ `pytest tests/test_api_routes.py` –ø—Ä–æ—Ö–æ–¥–∏—Ç
- ‚úÖ –í—Å–µ 8 —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã

**PR:** `feature/E1-2-fastapi-routes` (200‚Äì300 —Å—Ç—Ä–æ–∫)

---

### 1.3: FAB-–º–µ–º–±—Ä–∞–Ω–∞ (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è)

**–ú–æ–¥—É–ª—å:** `src/atlas/fab/router.py`

```python
from typing import List, Dict, Any
from collections import defaultdict

def route_search(query: str, levels: List[str], k: int) -> Dict[str, List[dict]]:
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è fan-out –∫ —Ç—Ä—ë–º —É—Ä–æ–≤–Ω—è–º –∏–Ω–¥–µ–∫—Å–æ–≤ (mock)."""
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –±—É–¥–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ –∫ sent/para/doc –∏–Ω–¥–µ–∫—Å–∞–º
    results = {
        "sent": mock_knn("sentence", query, k),
        "para": mock_knn("paragraph", query, k),
        "doc": mock_knn("document", query, k),
    }
    return results

def fuse_rrf(buckets: List[List[Dict[str, Any]]], k: int = 60) -> List[Dict[str, Any]]:
    """RRF fusion: score = Œ£ 1/(rank_i + k). –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ."""
    agg = defaultdict(float)
    
    for hits in buckets:
        for rank, hit in enumerate(hits):
            agg[hit["id"]] += 1.0 / (rank + k)
    
    merged = [{"id": hid, "score": score} for hid, score in agg.items()]
    merged.sort(key=lambda x: x["score"], reverse=True)
    return merged[:k]

def mock_knn(level: str, query: str, k: int) -> List[Dict[str, Any]]:
    """Mock KNN results (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ –ø–æ query)."""
    seed = hash((level, query)) & 0xfffffff
    hits = []
    for i in range(k):
        score = 1.0 - i / (k + 3)
        hits.append({"id": f"{level}-{i}", "score": score, "level": level})
    return hits
```

**–ú–æ–¥—É–ª—å:** `src/atlas/fab/clients.py`

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Any

class IndexClient(ABC):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–ª–∏–µ–Ω—Ç–∞ –∏–Ω–¥–µ–∫—Å–∞."""
    
    @abstractmethod
    async def knn(self, query: List[float], k: int) -> List[Dict[str, Any]]:
        pass

class HNSWClient(IndexClient):
    """Mock HNSW –∫–ª–∏–µ–Ω—Ç (–ø–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞)."""
    async def knn(self, query: List[float], k: int) -> List[Dict[str, Any]]:
        # TODO: —Ä–µ–∞–ª—å–Ω–∞—è HNSW –ø—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞
        return []

class FAISSClient(IndexClient):
    """Mock FAISS –∫–ª–∏–µ–Ω—Ç (–ø–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞)."""
    async def knn(self, query: List[float], k: int) -> List[Dict[str, Any]]:
        # TODO: —Ä–µ–∞–ª—å–Ω—ã–π FAISS –ø—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞
        return []
```

**Acceptance:**
- ‚úÖ `from atlas.fab.router import fuse_rrf, route_search` —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚úÖ RRF –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –≤–≤–æ–¥ ‚Üí –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
- ‚úÖ `pytest tests/test_fab_router.py` –ø—Ä–æ—Ö–æ–¥–∏—Ç
- ‚úÖ `make smoke` –∑–µ–ª—ë–Ω—ã–π (–ø—Ä–æ–≤–µ—Ä—è–µ—Ç reproducibility)

**PR:** `feature/E1-3-fab-router` (150‚Äì200 —Å—Ç—Ä–æ–∫)

---

### 1.4: ConfigLoader –≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é API

**–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** `src/atlas/api/routes.py`

```python
from src.atlas.configs import ConfigLoader

# –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
def on_startup():
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥–∏ –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å
    routes = ConfigLoader.get_api_routes()
    indices = ConfigLoader.get_all_index_configs()
    metrics = ConfigLoader.get_metrics_config()
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –≤—Å—ë —Å–∫–∞—á–∏–ª–æ—Å—å
    assert routes is not None, "routes.yaml –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è"
    assert indices is not None, "index configs –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å"
    
    print("‚úÖ Configs loaded and validated")

app.add_event_handler("startup", on_startup)
```

**Acceptance:**
- ‚úÖ –°–ª–æ–º–∞–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ ‚Üí `make validate` –ø–∞–¥–∞–µ—Ç ‚ùå
- ‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ ‚Üí `make validate` –∑–µ–ª—ë–Ω—ã–π ‚úÖ
- ‚úÖ `make smoke` —Ä–∞–±–æ—Ç–∞–µ—Ç

**PR:** `feature/E1-4-configloader-integration` (50‚Äì100 —Å—Ç—Ä–æ–∫)

---

## E2 ‚Äî –ò–Ω–¥–µ–∫—Å—ã & MANIFEST (–Ω–µ–¥–µ–ª—è 2)

### 2.1: Index builders

**–°–∫—Ä–∏–ø—Ç:** `scripts/build_indexes.py`

```python
#!/usr/bin/env python3
"""–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–æ–≤."""

import pathlib
import json
from src.atlas.configs import ConfigLoader

def build_indexes():
    """–°–æ–∑–¥–∞—Ç—å stub –∏–Ω–¥–µ–∫—Å—ã —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏."""
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥–∏
    sent_cfg = ConfigLoader.get_index_config("sentence")
    para_cfg = ConfigLoader.get_index_config("paragraph")
    doc_cfg = ConfigLoader.get_index_config("document")
    
    # –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    idx_dir = pathlib.Path("indexes")
    idx_dir.mkdir(exist_ok=True)
    
    # –°–æ–∑–¥–∞—Ç—å stub HNSW –∏–Ω–¥–µ–∫—Å—ã (–ø–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ metadata JSON)
    for level, cfg in [("sent", sent_cfg), ("para", para_cfg)]:
        meta = {
            "type": "hnsw",
            "level": level,
            "M": cfg["M"],
            "ef_construction": cfg["ef_construction"],
            "ef_search": cfg["ef_search"],
            "vector_dim": 384,
            "num_vectors": 0  # stub
        }
        with (idx_dir / f"{level}.hnsw.meta.json").open("w") as f:
            json.dump(meta, f, indent=2)
    
    # –°–æ–∑–¥–∞—Ç—å stub FAISS –∏–Ω–¥–µ–∫—Å
    doc_meta = {
        "type": "faiss",
        "level": "doc",
        "nlist": doc_cfg["ivf"]["nlist"],
        "m": doc_cfg["pq"]["m"],
        "nbits": doc_cfg["pq"]["nbits"],
        "vector_dim": 384,
        "num_vectors": 0  # stub
    }
    with (idx_dir / "doc.faiss.meta.json").open("w") as f:
        json.dump(doc_meta, f, indent=2)
    
    print("‚úÖ Index stubs created")

if __name__ == "__main__":
    build_indexes()
```

**Acceptance:**
- ‚úÖ `python scripts/build_indexes.py` —Å–æ–∑–¥–∞—ë—Ç `indexes/*.meta.json`
- ‚úÖ `make validate` –∑–µ–ª—ë–Ω—ã–π
- ‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –∫–æ–Ω—Ñ–∏–≥–æ–º

**PR:** `feature/E2-1-index-builders` (100‚Äì150 —Å—Ç—Ä–æ–∫)

---

### 2.2: MANIFEST –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä

**–°–∫—Ä–∏–ø—Ç:** `tools/make_manifest.py`

```python
#!/usr/bin/env python3
"""–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å MANIFEST.v0_2.json —Å SHA256 –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏."""

import json
import pathlib
import hashlib
import subprocess
from datetime import datetime

def sha256_file(fpath):
    """–í—ã—á–∏—Å–ª–∏—Ç—å SHA256 —Ñ–∞–π–ª–∞."""
    h = hashlib.sha256()
    with open(fpath, "rb") as f:
        h.update(f.read())
    return h.hexdigest()

def get_git_info():
    """–ü–æ–ª—É—á–∏—Ç—å git commit –∏ branch."""
    try:
        commit = subprocess.check_output(
            ["git", "rev-parse", "HEAD"], text=True
        ).strip()
        branch = subprocess.check_output(
            ["git", "rev-parse", "--abbrev-ref", "HEAD"], text=True
        ).strip()
    except Exception:
        commit = "unknown"
        branch = "unknown"
    return {"commit": commit, "branch": branch}

def make_manifest(out_path="MANIFEST.v0_2.json"):
    """–°–æ–∑–¥–∞—Ç—å MANIFEST."""
    
    manifest = {
        "version": "0.2.0-beta",
        "created_at": datetime.utcnow().isoformat() + "Z",
        "git": get_git_info(),
        "models": {
            "teacher": {
                "name": "stub-teacher",
                "hash": "sha256:" + ("0" * 64),  # placeholder
                "url": "s3://stub/teacher"
            }
        },
        "indices": {
            "sentence": {
                "type": "hnsw",
                "hash": "sha256:" + sha256_file("indexes/sent.hnsw.meta.json"),
            },
            "paragraph": {
                "type": "hnsw",
                "hash": "sha256:" + sha256_file("indexes/para.hnsw.meta.json"),
            },
            "document": {
                "type": "faiss",
                "hash": "sha256:" + sha256_file("indexes/doc.faiss.meta.json"),
            }
        },
        "schema": "src/atlas/configs/indices/manifest_schema.json"
    }
    
    with open(out_path, "w") as f:
        json.dump(manifest, f, indent=2)
    
    print(f"‚úÖ MANIFEST written to {out_path}")

if __name__ == "__main__":
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--out", default="MANIFEST.v0_2.json")
    args = ap.parse_args()
    make_manifest(args.out)
```

**Acceptance:**
- ‚úÖ `python tools/make_manifest.py --out MANIFEST.v0_2.json` —Å–æ–∑–¥–∞—ë—Ç —Ñ–∞–π–ª
- ‚úÖ `python scripts/validate_baseline.py --manifest MANIFEST.v0_2.json` –ø—Ä–æ—Ö–æ–¥–∏—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é ‚úÖ
- ‚úÖ SHA256 —Ö–µ—à–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º

**PR:** `feature/E2-2-manifest-generator` (100‚Äì150 —Å—Ç—Ä–æ–∫)

---

## E3 ‚Äî –ú–µ—Ç—Ä–∏–∫–∏ (–±–∞–∑–æ–≤—ã–π –∫–∞—Ä–∫–∞—Å) (–Ω–µ–¥–µ–ª—è 2‚Äì3)

### 3.1: H-–º–µ—Ç—Ä–∏–∫ –∫–∞—Ä–∫–∞—Å

**–ú–æ–¥—É–ª—å:** `src/atlas/metrics/h_memory.py`

```python
"""H-Coherence –∏ H-Stability –≤—ã—á–∏—Å–ª–µ–Ω–∏—è."""

from typing import Dict, Any
from src.atlas.configs import ConfigLoader
import numpy as np

def compute_h_coherence(sent_embeddings: np.ndarray, para_embeddings: np.ndarray) -> float:
    """
    H-Coherence –º–µ–∂–¥—É sentence –∏ paragraph —É—Ä–æ–≤–Ω—è–º–∏.
    –§–æ—Ä–º—É–ª–∞ (stub): —Å—Ä–µ–¥–Ω–∏–π cosine similarity.
    """
    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å
    sent_norm = np.linalg.norm(sent_embeddings, axis=1, keepdims=True)
    para_norm = np.linalg.norm(para_embeddings, axis=1, keepdims=True)
    
    sent_normalized = sent_embeddings / (sent_norm + 1e-10)
    para_normalized = para_embeddings / (para_norm + 1e-10)
    
    # –°—Ä–µ–¥–Ω–∏–π cosine similarity (stub —É–ø—Ä–æ—â–µ–Ω–∏–µ)
    min_len = min(len(sent_normalized), len(para_normalized))
    scores = [
        np.dot(sent_normalized[i], para_normalized[i])
        for i in range(min_len)
    ]
    return np.mean(scores) if scores else 0.0

def compute_h_stability(embeddings_t0: np.ndarray, embeddings_t1: np.ndarray) -> float:
    """
    H-Stability: –¥—Ä–µ–π—Ñ embeddings –º–µ–∂–¥—É –¥–≤—É–º—è –º–æ–º–µ–Ω—Ç–∞–º–∏.
    –§–æ—Ä–º—É–ª–∞ (stub): —Å—Ä–µ–¥–Ω—è—è L2 –Ω–æ—Ä–º–∞ —Ä–∞–∑–Ω–∏—Ü—ã.
    """
    diff = np.linalg.norm(embeddings_t0 - embeddings_t1, axis=1)
    return float(np.mean(diff))

def check_h_metrics(sent_emb, para_emb, doc_emb) -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å H-–º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ—Ç–∏–≤ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π."""
    
    cfg = ConfigLoader.get_metrics_config()
    
    # –í—ã—á–∏—Å–ª–∏—Ç—å H-Coherence
    h_coh_sp = compute_h_coherence(sent_emb, para_emb)
    h_coh_pd = compute_h_coherence(para_emb, doc_emb)
    
    # –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Ä–æ–≥–∏
    h_coh_sp_target = cfg["h_coherence"]["sent_to_para"]["target"]
    h_coh_pd_target = cfg["h_coherence"]["para_to_doc"]["target"]
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
    passed = (h_coh_sp >= h_coh_sp_target and h_coh_pd >= h_coh_pd_target)
    
    return {
        "h_coherence": {
            "sent_to_para": {"value": h_coh_sp, "target": h_coh_sp_target, "passed": h_coh_sp >= h_coh_sp_target},
            "para_to_doc": {"value": h_coh_pd, "target": h_coh_pd_target, "passed": h_coh_pd >= h_coh_pd_target},
        },
        "passed": passed
    }
```

**Acceptance:**
- ‚úÖ `from atlas.metrics.h_memory import check_h_metrics` —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚úÖ –ü–æ—Ä–æ–≥–∏ —á–∏—Ç–∞—é—Ç—Å—è –∏–∑ `h_metrics.yaml`
- ‚úÖ `pytest tests/test_h_metrics.py` –ø—Ä–æ—Ö–æ–¥–∏—Ç

**PR:** `feature/E3-1-h-metrics-framework` (150‚Äì200 —Å—Ç—Ä–æ–∫)

---

### 3.2: –°–∫—Ä–∏–ø—Ç –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–µ—Ç—Ä–∏–∫

**–°–∫—Ä–∏–ø—Ç:** `scripts/run_h_metrics.py`

```python
#!/usr/bin/env python3
"""–ó–∞–ø—É—Å—Ç–∏—Ç—å H-–º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–≤–µ—Ä–∫—É –ª–æ–∫–∞–ª—å–Ω–æ."""

import json
import numpy as np
from src.atlas.metrics.h_memory import check_h_metrics

def run_h_metrics():
    """Mock embeddings –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å metrics."""
    
    # –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å mock embeddings (L2-normalized)
    num_samples = 100
    dim = 384
    
    sent_emb = np.random.randn(num_samples, dim)
    sent_emb /= np.linalg.norm(sent_emb, axis=1, keepdims=True)
    
    para_emb = np.random.randn(num_samples, dim)
    para_emb /= np.linalg.norm(para_emb, axis=1, keepdims=True)
    
    doc_emb = np.random.randn(num_samples, dim)
    doc_emb /= np.linalg.norm(doc_emb, axis=1, keepdims=True)
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å H-–º–µ—Ç—Ä–∏–∫–∏
    result = check_h_metrics(sent_emb, para_emb, doc_emb)
    
    # –í—ã–≤–µ—Å—Ç–∏ –æ—Ç—á—ë—Ç
    print(json.dumps(result, indent=2))
    
    if result["passed"]:
        print("\n‚úÖ H-metrics PASSED")
        return 0
    else:
        print("\n‚ùå H-metrics FAILED")
        return 1

if __name__ == "__main__":
    exit(run_h_metrics())
```

**Acceptance:**
- ‚úÖ `python scripts/run_h_metrics.py` —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚úÖ JSON –æ—Ç—á—ë—Ç —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –ø–æ—Ä–æ–≥–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
- ‚úÖ Exit code 0 (pass) –∏–ª–∏ 1 (fail)

**PR:** `feature/E3-2-h-metrics-script` (100‚Äì150 —Å—Ç—Ä–æ–∫)

---

## CI / –ó–∞—â–∏—Ç–∞ –≤–µ—Ç–æ–∫

### GitHub Actions: `.github/workflows/validate.yml`

```yaml
name: Validate

on: [push, pull_request]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -e .[dev]
      
      - name: Validate configs (strict)
        run: make validate
      
      - name: Smoke tests
        run: make smoke
      
      - name: Run tests
        run: pytest tests/ -v
```

### Branch Protection Rules

- ‚úÖ Require status checks (validate, smoke, tests)
- ‚úÖ Require PRs reviewed
- ‚úÖ Auto-delete head branches

---

## Acceptance –Ω–∞ –∫–∞–∂–¥—ã–π —ç—Ç–∞–ø

### E1 ‚úÖ
- [ ] Pydantic-—Å—Ö–µ–º—ã –≤ `src/atlas/api/schemas.py`
- [ ] 8 FastAPI –º–∞—Ä—à—Ä—É—Ç–æ–≤ –≤ `src/atlas/api/routes.py`
- [ ] FAB-–º–µ–º–±—Ä–∞–Ω–∞ (router.py, clients.py)
- [ ] ConfigLoader –≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
- [ ] `make validate` üü¢
- [ ] `make smoke` üü¢
- [ ] `/health` ‚Üí 200
- [ ] `pytest tests/test_api_*.py` üü¢

### E2 ‚úÖ
- [ ] Index builders —Å–æ–∑–¥–∞—é—Ç stub –∏–Ω–¥–µ–∫—Å—ã
- [ ] MANIFEST –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∏ –ø—Ä–æ—Ö–æ–¥–∏—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é
- [ ] `python scripts/build_indexes.py` —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] `python tools/make_manifest.py --out MANIFEST.v0_2.json` —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] `python scripts/validate_baseline.py --manifest MANIFEST.v0_2.json` üü¢

### E3 ‚úÖ
- [ ] H-–º–µ—Ç—Ä–∏–∫ –∫–∞—Ä–∫–∞—Å –≤ `src/atlas/metrics/h_memory.py`
- [ ] –°–∫—Ä–∏–ø—Ç `scripts/run_h_metrics.py` —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –ü–æ—Ä–æ–≥–∏ —á–∏—Ç–∞—é—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
- [ ] `pytest tests/test_h_metrics.py` üü¢

---

## –ë—ã—Å—Ç—Ä—ã–µ –∫–æ–º–∞–Ω–¥—ã

```bash
# –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞
uvicorn src.atlas.api.app:app --reload

# –í–∞–ª–∏–¥–∞—Ü–∏—è
make validate
make smoke

# –¢–µ—Å—Ç—ã
pytest tests/ -v

# MANIFEST
python tools/make_manifest.py --out MANIFEST.v0_2.json
python scripts/validate_baseline.py --manifest MANIFEST.v0_2.json --strict

# H-–º–µ—Ç—Ä–∏–∫–∏
python scripts/run_h_metrics.py
```

---

## –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ: –ì—Ä–∞–Ω–∏—Ü—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

‚ùå **–ó–∞–ø—Ä–µ—â–µ–Ω–æ:**
- –ü–æ–ª–∏—Ç–∏–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è / –Ω–∞–º–µ—Ä–µ–Ω–∏–π
- –û–Ω–ª–∞–π–Ω-–æ–±—É—á–µ–Ω–∏–µ
- Hidden state –≤–Ω—É—Ç—Ä–∏ FAB
- Auto-reconfig –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω–æ:**
- FAB = stateless –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è + –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π RRF
- –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∫–æ–Ω—Ñ–∏–≥–∞—Ö (routes.yaml, *.yaml, metrics.yaml)
- –ò–∑–º–µ–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ git ‚Üí review ‚Üí deploy + –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞
- MANIFEST –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤—Å–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã

---

**–°—Ç–∞—Ç—É—Å:** üü¢ **READY TO START E1**

